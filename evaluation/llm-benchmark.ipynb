{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import All Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded\n",
    "from tira.rest_api_client import Client\n",
    "ensure_pyterrier_is_loaded()\n",
    "import pyterrier as pt\n",
    "#import pandas as pd\n",
    "\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset and the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "dataset = 'ir-acl-anthology-20240504-training'\n",
    "pt_dataset = pt.get_dataset(f'irds:ir-benchmarks/{dataset}')\n",
    "\n",
    "# A (pre-built) PyTerrier index loaded from TIRA\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLAMA and GPT Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_rm3 = bm25 >> pt.rewrite.RM3(index) >> bm25\n",
    "bm25_kl = bm25 >> pt.rewrite.KLQueryExpansion(index) >> bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT\n",
    "gpt_cot = tira.pt.transform_queries('workshop-on-open-web-search/tu-dresden-03/qe-gpt3.5-cot', dataset, prefix='llm_expansion_')\n",
    "gpt_sq_fs = tira.pt.transform_queries('workshop-on-open-web-search/tu-dresden-03/qe-gpt3.5-sq-fs', dataset, prefix='llm_expansion_')\n",
    "gpt_sq_zs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-gpt3.5-sq-zs', dataset, prefix='llm_expansion_')\n",
    "\n",
    "# LLAMA\n",
    "llama_cot = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-llama-cot', dataset, prefix='llm_expansion_')\n",
    "llama_sq_fs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-llama-sq-fs', dataset, prefix='llm_expansion_')\n",
    "llama_sq_zs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-llama-sq-zs', dataset, prefix='llm_expansion_')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = pt.autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()\n",
    "\n",
    "def pt_tokenize(text):\n",
    "    return ' '.join(tokeniser.getTokens(text))\n",
    "\n",
    "def expand_query(topic):\n",
    "  ret = ' '.join([topic['query'], topic['query'], topic['query'],  topic['query'],  topic['query'], topic['llm_expansion_query']])\n",
    "\n",
    "  # apply the tokenization\n",
    "  return pt_tokenize(ret)\n",
    "\n",
    "pt_expand_query = pt.apply.query(expand_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_gpt_cot = (gpt_cot >> pt_expand_query) >> bm25\n",
    "pipeline_gpt_sq_fs = (gpt_sq_fs >> pt_expand_query) >> bm25\n",
    "pipeline_gpt_sq_zs = (gpt_sq_zs >> pt_expand_query) >> bm25\n",
    "\n",
    "pipeline_llama_cot = (llama_cot >> pt_expand_query) >> bm25\n",
    "pipeline_llama_sq_fs = (llama_sq_fs >> pt_expand_query) >> bm25\n",
    "pipeline_llama_sq_zs = (llama_sq_zs >> pt_expand_query) >> bm25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:36:06.233 [main] WARN org.terrier.querying.RM1 - Did not identify any usable candidate expansion terms from docid 125137 among 5 possibilities\n",
      "15:36:06.896 [main] WARN org.terrier.querying.RM1 - Did not identify any usable candidate expansion terms from docid 116910 among 4 possibilities\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recall_1000</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>recip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.825376</td>\n",
       "      <td>0.374041</td>\n",
       "      <td>0.579877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25+RM3</td>\n",
       "      <td>0.825062</td>\n",
       "      <td>0.333132</td>\n",
       "      <td>0.556066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25+KL</td>\n",
       "      <td>0.831915</td>\n",
       "      <td>0.379452</td>\n",
       "      <td>0.565090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT-COT</td>\n",
       "      <td>0.825698</td>\n",
       "      <td>0.305605</td>\n",
       "      <td>0.524838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT-SQ-FS</td>\n",
       "      <td>0.835660</td>\n",
       "      <td>0.377988</td>\n",
       "      <td>0.615292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GPT-SQ-ZS</td>\n",
       "      <td>0.829955</td>\n",
       "      <td>0.364157</td>\n",
       "      <td>0.644563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-COT</td>\n",
       "      <td>0.783448</td>\n",
       "      <td>0.253630</td>\n",
       "      <td>0.469709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Llama-SQ-FS</td>\n",
       "      <td>0.837392</td>\n",
       "      <td>0.368856</td>\n",
       "      <td>0.608088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama-SQ-ZS</td>\n",
       "      <td>0.839125</td>\n",
       "      <td>0.346550</td>\n",
       "      <td>0.588296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  recall_1000  ndcg_cut.10  recip_rank\n",
       "0         BM25     0.825376     0.374041    0.579877\n",
       "1     BM25+RM3     0.825062     0.333132    0.556066\n",
       "2      BM25+KL     0.831915     0.379452    0.565090\n",
       "3      GPT-COT     0.825698     0.305605    0.524838\n",
       "4    GPT-SQ-FS     0.835660     0.377988    0.615292\n",
       "5    GPT-SQ-ZS     0.829955     0.364157    0.644563\n",
       "6    Llama-COT     0.783448     0.253630    0.469709\n",
       "7  Llama-SQ-FS     0.837392     0.368856    0.608088\n",
       "8  Llama-SQ-ZS     0.839125     0.346550    0.588296"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    retr_systems=[bm25, bm25_rm3, bm25_kl, pipeline_gpt_cot, pipeline_gpt_sq_fs, pipeline_gpt_sq_zs, pipeline_llama_cot, pipeline_llama_sq_fs, pipeline_llama_sq_zs],\n",
    "    topics=pt_dataset.get_topics('text'),\n",
    "    qrels=pt_dataset.get_qrels(),\n",
    "    names=['BM25', 'BM25+RM3', 'BM25+KL', 'GPT-COT','GPT-SQ-FS', 'GPT-SQ-ZS', 'Llama-COT', 'Llama-SQ-FS', 'Llama-SQ-ZS'],\n",
    "    eval_metrics=['recall_1000', 'ndcg_cut.10', 'recip_rank']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
