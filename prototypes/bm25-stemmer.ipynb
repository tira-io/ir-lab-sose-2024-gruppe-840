{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import All Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "ensure_pyterrier_is_loaded()\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "from tqdm import tqdm\n",
    "from jnius import autoclass\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "tira = Client()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset and the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "dataset = 'antique-test-20230107-training'\n",
    "pt_dataset = pt.get_dataset(f'irds:ir-benchmarks/{dataset}')\n",
    "bm25 = tira.pt.from_submission('ir-benchmarks/tira-ir-starter/BM25 Re-Rank (tira-ir-starter-pyterrier)', dataset)\n",
    "\n",
    "# A (pre-built) PyTerrier index loaded from TIRA\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemmer and Lemmatizer  (funktioniert leider nicht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variante 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-sose-2024/ir-acl-anthology-20240504-training documents: 100%|██████████| 126958/126958 [00:02<00:00, 59212.78it/s]\n",
      "ir-lab-sose-2024/ir-acl-anthology-20240504-training documents: 100%|██████████| 126958/126958 [00:02<00:00, 57026.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:32:40.883 [ForkJoinPool-13-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (2020.mir_conference-2020.1) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-sose-2024/ir-acl-anthology-20240504-training documents: 100%|██████████| 126958/126958 [00:18<00:00, 7013.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:32:46.680 [ForkJoinPool-13-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 3 empty documents\n",
      "TerrierStemmer.porter\n"
     ]
    }
   ],
   "source": [
    "def stem(t):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(t)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, stemmer=lemmatizer)\n",
    "index_ref = indexer.index(pt_dataset.get_corpus_iter())\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "bm25_stem = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "\n",
    "\n",
    "def stem(t):\n",
    "    stemmer = LancasterStemmer()\n",
    "    return stemmer.stem(t)\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, stemmer=stemmer)\n",
    "index_ref = indexer.index(pt_dataset.get_corpus_iter())\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "\n",
    "bm25_lem = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variante 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:24:11.578 [ForkJoinPool-15-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (2020.mir_conference-2020.1) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-sose-2024/ir-acl-anthology-20240504-training documents: 100%|██████████| 126958/126958 [03:52<00:00, 546.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:02.649 [ForkJoinPool-15-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 2 empty documents\n"
     ]
    }
   ],
   "source": [
    "def stem_text(text):\n",
    "    stemmer = LancasterStemmer()\n",
    "    return \" \".join([stemmer.stem(word) for word in nltk.word_tokenize(text)])\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text)])\n",
    "\n",
    "def document_iterator(docs, transform_func):\n",
    "    for doc in docs:\n",
    "        doc[\"text\"] = transform_func(doc[\"text\"])\n",
    "        yield doc\n",
    "\n",
    "\n",
    "transform_func = stem_text  # oder lemmatize_text\n",
    "\n",
    "\n",
    "indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True)\n",
    "index_ref = indexer.index(document_iterator(pt_dataset.get_corpus_iter(), transform_func))\n",
    "\n",
    "class NLTKStemmerTransformer(pt.Transformer):\n",
    "    def __init__(self, stemmer):\n",
    "        self.stemmer = stemmer\n",
    "\n",
    "    def transform(self, queries):\n",
    "        queries['query'] = queries['query'].apply(stem_text)\n",
    "        return queries\n",
    "\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "nltk_stemmer_transformer = NLTKStemmerTransformer(stemmer)\n",
    "\n",
    "\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "\n",
    "bm25_stem = nltk_stemmer_transformer >> pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recall_1000</th>\n",
       "      <th>ndcg_cut_5</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>recip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.825376</td>\n",
       "      <td>0.39365</td>\n",
       "      <td>0.374041</td>\n",
       "      <td>0.579877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bm25_stem</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  recall_1000  ndcg_cut_5  ndcg_cut.10  recip_rank\n",
       "0       BM25     0.825376     0.39365     0.374041    0.579877\n",
       "1  bm25_stem     0.000000     0.00000     0.000000    0.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pt.Experiment(\n",
    "    retr_systems=[bm25, bm25_stem],\n",
    "    topics=pt_dataset.get_topics('text'),\n",
    "    qrels=pt_dataset.get_qrels(),\n",
    "    names=['BM25', 'bm25_stem'],\n",
    "    eval_metrics=['recall_1000', 'ndcg_cut_5', 'ndcg_cut.10', 'recip_rank']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leider kommt immer wieder 0.0 raus egal welche Variante ich benutze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Expansion by Query Prediction with docT5query\n",
    "The basic idea is to train a model, that when given an input document, generates questions that the document might answer (or more broadly, queries for which the document might be relevant). These predicted questions (or queries) are then appended to the original documents, which are then indexed as before. The docT5query model gets its name from the use of T5 as the expansion model.\n",
    "\n",
    "The primary advantage of this approach is that expensive neural inference is pushed to indexing time, which means that \"bag of words\" queries against an inverted index built on the augmented document collection are only slightly slower (due to longer documents) — but the retrieval results are much better.\n",
    "\n",
    "First we check, if our corpus has a high recall or a lower. Our Corpus in this case is the union of the IR Anthology and the ACL Anthology. The recall may change if we use another corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recall_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  recall_1000\n",
       "0  BM25     0.788732"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "pt.Experiment(\n",
    "    retr_systems=[bm25],\n",
    "    topics=pt_dataset.get_topics('text'),\n",
    "    qrels=pt_dataset.get_qrels(),\n",
    "    names=['BM25'],\n",
    "    eval_metrics=['recall_1000']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have already a high recall. This is important for the way we implement the docT5query.\n",
    "More information about the implementation in the [Tutorial](https://github.com/tira-io/teaching-ir-with-shared-tasks/blob/main/tutorials/tutorial-doc-t5-query.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_t5_query(dataset):\n",
    "    docs = tira.get_run_output('ir-benchmarks/seanmacavaney/DocT5Query', dataset) + '/documents.jsonl.gz'\n",
    "    with gzip.open(docs, 'rt') as f:\n",
    "        for l in tqdm(f):\n",
    "            l = json.loads(l)\n",
    "            l['text'] = l['querygen']\n",
    "            l['docno'] = l['doc_id']\n",
    "            del l['doc_id']\n",
    "            del l['querygen']\n",
    "            yield l\n",
    "\n",
    "def doc_t5_query_index(dataset):\n",
    "    indexer = pt.IterDictIndexer(\"/tmp/index2\", overwrite=True, meta={'docno': 100, 'text': 20480})\n",
    "    index_ref = indexer.index(doc_t5_query(dataset))\n",
    "    return pt.IndexFactory.of(index_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:03:25.536 [ForkJoinPool-16-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (3052500_1) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "403666it [00:27, 14603.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:03:55.057 [ForkJoinPool-16-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 113 empty documents\n"
     ]
    }
   ],
   "source": [
    "indexD = doc_t5_query_index(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188633it [00:07, 23826.40it/s]\n"
     ]
    }
   ],
   "source": [
    "docs_retrieved_by_bm25 = {}\n",
    "\n",
    "bm25_result = bm25(pt_dataset.get_topics('title'))\n",
    "\n",
    "for _, i in tqdm(bm25_result.iterrows()):\n",
    "    qid, docno = str(i['qid']), str(i['docno'])\n",
    "\n",
    "    if qid not in docs_retrieved_by_bm25:\n",
    "        docs_retrieved_by_bm25[qid] = set()\n",
    "    \n",
    "    docs_retrieved_by_bm25[qid].add(docno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "omit_already_retrieved_docs = lambda i: i[i.apply(lambda j: str(j['docno']) not in docs_retrieved_by_bm25[str(j['qid'])], axis=1)]\n",
    "omit_already_retrieved_docs = pt.apply.generic(omit_already_retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_doct5query = pt.BatchRetrieve(indexD, wmodel=\"BM25\")\n",
    "bm25_doct5query_new = bm25_doct5query >> omit_already_retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DocT5Query bringt uns im normalen dataset nicht so viel, also lassen wir es weg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-benchmarks/antique-test-20230107-training documents:   0%|          | 1931/403666 [00:02<03:54, 1710.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:16:56.912 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (2824443_2) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-benchmarks/antique-test-20230107-training documents: 100%|██████████| 403666/403666 [00:42<00:00, 9393.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:17:42.105 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 1570 empty documents\n"
     ]
    }
   ],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "def create_index(documents, stopwords):\n",
    "    indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, meta={'docno': 100, 'text': 20480}, stopwords=customStopwords)\n",
    "    index_ref = indexer.index(documents)\n",
    "    return pt.IndexFactory.of(index_ref)\n",
    "\n",
    "customStopwords =[\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', \n",
    "    'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', \n",
    "    'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', \n",
    "    'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', \n",
    "    'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', \n",
    "    'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', \n",
    "    'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', \n",
    "    'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', \n",
    "    'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', \n",
    "    'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', \n",
    "    'will', 'just', 'don', 'should', 'now'\n",
    "]\n",
    "\n",
    "index = create_index(pt_dataset.get_corpus_iter(), customStopwords)\n",
    "\n",
    "bm25_stopwords = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Expansion with Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_rm3 = bm25 >> pt.rewrite.RM3(index) >> bm25\n",
    "bm25_kl = bm25 >> pt.rewrite.KLQueryExpansion(index) >> bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm expansions with gpt\n",
    "gpt_cot = tira.pt.transform_queries('workshop-on-open-web-search/tu-dresden-03/qe-gpt3.5-cot', dataset, prefix='llm_expansion_')\n",
    "gpt_sq_fs = tira.pt.transform_queries('workshop-on-open-web-search/tu-dresden-03/qe-gpt3.5-sq-fs', dataset, prefix='llm_expansion_')\n",
    "gpt_sq_zs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-gpt3.5-sq-zs', dataset, prefix='llm_expansion_')\n",
    "\n",
    "# llm expansions with llama\n",
    "llama_cot = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-llama-cot', dataset, prefix='llm_expansion_')\n",
    "llama_sq_fs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-llama-sq-fs', dataset, prefix='llm_expansion_')\n",
    "llama_sq_zs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-llama-sq-zs', dataset, prefix='llm_expansion_')\n",
    "\n",
    "# llm expansions with flan-ul2\n",
    "flan_cot = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-flan-ul2-cot', dataset, prefix='llm_expansion_')\n",
    "flan_sq_fs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-flan-ul2-sq-fs', dataset, prefix='llm_expansion_')\n",
    "flan_sq_zs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-flan-ul2-sq-zs', dataset, prefix='llm_expansion_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = pt.autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()\n",
    "\n",
    "def pt_tokenize(text):\n",
    "    return ' '.join(tokeniser.getTokens(text))\n",
    "\n",
    "def expand_query(topic):\n",
    "  ret = ' '.join([topic['query'], topic['query'], topic['query'],  topic['query'],  topic['query'], topic['llm_expansion_query']])\n",
    "\n",
    "  # apply the tokenization\n",
    "  return pt_tokenize(ret)\n",
    "\n",
    "# we wrap this into an pyterrier transformer\n",
    "# Documentation: https://pyterrier.readthedocs.io/en/latest/apply.html\n",
    "pt_expand_query = pt.apply.query(expand_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_gpt_cot = (gpt_cot >> pt_expand_query) >> bm25\n",
    "pipeline_gpt_sq_fs = (gpt_sq_fs >> pt_expand_query) >> bm25\n",
    "pipeline_gpt_sq_zs = (gpt_sq_zs >> pt_expand_query) >> bm25\n",
    "\n",
    "pipeline_llama_cot = (llama_cot >> pt_expand_query) >> bm25\n",
    "pipeline_llama_sq_fs = (llama_sq_fs >> pt_expand_query) >> bm25\n",
    "pipeline_llama_sq_zs = (llama_sq_zs >> pt_expand_query) >> bm25\n",
    "\n",
    "pipeline_flan_cot = (flan_cot >> pt_expand_query) >> bm25\n",
    "pipeline_flan_sq_fs = (flan_sq_fs >> pt_expand_query) >> bm25\n",
    "pipeline_flan_sq_zs = (flan_sq_zs >> pt_expand_query) >> bm25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bo1 Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo1_expansion = bm25 >> pt.rewrite.Bo1QueryExpansion(index)\n",
    "# build final pipeline for retrieval\n",
    "bm25_bo1 = bo1_expansion >> bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recall_1000</th>\n",
       "      <th>ndcg_cut_5</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>recip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.529428</td>\n",
       "      <td>0.510402</td>\n",
       "      <td>0.934803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25_stopwords</td>\n",
       "      <td>0.794154</td>\n",
       "      <td>0.536473</td>\n",
       "      <td>0.516196</td>\n",
       "      <td>0.948333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25_Bo1</td>\n",
       "      <td>0.788942</td>\n",
       "      <td>0.532035</td>\n",
       "      <td>0.505874</td>\n",
       "      <td>0.949333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BM25+RM3</td>\n",
       "      <td>0.779658</td>\n",
       "      <td>0.509709</td>\n",
       "      <td>0.489250</td>\n",
       "      <td>0.934375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BM25+KL</td>\n",
       "      <td>0.788479</td>\n",
       "      <td>0.532529</td>\n",
       "      <td>0.503925</td>\n",
       "      <td>0.949333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BM25+GPT-COT</td>\n",
       "      <td>0.806138</td>\n",
       "      <td>0.541391</td>\n",
       "      <td>0.506853</td>\n",
       "      <td>0.875463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BM25+GPT-SQ-FS</td>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.541749</td>\n",
       "      <td>0.518511</td>\n",
       "      <td>0.938364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BM25+GPT-SQ-ZS</td>\n",
       "      <td>0.790430</td>\n",
       "      <td>0.536149</td>\n",
       "      <td>0.501605</td>\n",
       "      <td>0.921401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BM25+Llama-COT</td>\n",
       "      <td>0.793485</td>\n",
       "      <td>0.523303</td>\n",
       "      <td>0.495643</td>\n",
       "      <td>0.866429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BM25+Llama-SQ-FS</td>\n",
       "      <td>0.797566</td>\n",
       "      <td>0.547980</td>\n",
       "      <td>0.517811</td>\n",
       "      <td>0.936454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BM25+Llama-SQ-ZS</td>\n",
       "      <td>0.803869</td>\n",
       "      <td>0.562714</td>\n",
       "      <td>0.529252</td>\n",
       "      <td>0.930113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BM25+Flan-COT</td>\n",
       "      <td>0.796139</td>\n",
       "      <td>0.521862</td>\n",
       "      <td>0.496685</td>\n",
       "      <td>0.895637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BM25+Flan-SQ-FS</td>\n",
       "      <td>0.791370</td>\n",
       "      <td>0.531894</td>\n",
       "      <td>0.507946</td>\n",
       "      <td>0.932898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BM25+Flan-SQ-ZS</td>\n",
       "      <td>0.798648</td>\n",
       "      <td>0.525873</td>\n",
       "      <td>0.502075</td>\n",
       "      <td>0.898631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name  recall_1000  ndcg_cut_5  ndcg_cut.10  recip_rank\n",
       "0               BM25     0.788732    0.529428     0.510402    0.934803\n",
       "1     BM25_stopwords     0.794154    0.536473     0.516196    0.948333\n",
       "2           BM25_Bo1     0.788942    0.532035     0.505874    0.949333\n",
       "3           BM25+RM3     0.779658    0.509709     0.489250    0.934375\n",
       "4            BM25+KL     0.788479    0.532529     0.503925    0.949333\n",
       "5       BM25+GPT-COT     0.806138    0.541391     0.506853    0.875463\n",
       "6     BM25+GPT-SQ-FS     0.797366    0.541749     0.518511    0.938364\n",
       "7     BM25+GPT-SQ-ZS     0.790430    0.536149     0.501605    0.921401\n",
       "8     BM25+Llama-COT     0.793485    0.523303     0.495643    0.866429\n",
       "9   BM25+Llama-SQ-FS     0.797566    0.547980     0.517811    0.936454\n",
       "10  BM25+Llama-SQ-ZS     0.803869    0.562714     0.529252    0.930113\n",
       "11     BM25+Flan-COT     0.796139    0.521862     0.496685    0.895637\n",
       "12   BM25+Flan-SQ-FS     0.791370    0.531894     0.507946    0.932898\n",
       "13   BM25+Flan-SQ-ZS     0.798648    0.525873     0.502075    0.898631"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    retr_systems=[bm25, bm25_stopwords, bm25_bo1, bm25_rm3, bm25_kl, pipeline_gpt_cot, pipeline_gpt_sq_fs, pipeline_gpt_sq_zs, pipeline_llama_cot, pipeline_llama_sq_fs, pipeline_llama_sq_zs, pipeline_flan_cot, pipeline_flan_sq_fs, pipeline_flan_sq_zs],\n",
    "    topics=pt_dataset.get_topics('text'),\n",
    "    qrels=pt_dataset.get_qrels(),\n",
    "    names=['BM25', 'BM25_stopwords','BM25_Bo1', 'BM25+RM3', 'BM25+KL', 'BM25+GPT-COT', 'BM25+GPT-SQ-FS', 'BM25+GPT-SQ-ZS', 'BM25+Llama-COT', 'BM25+Llama-SQ-FS', 'BM25+Llama-SQ-ZS', 'BM25+Flan-COT', 'BM25+Flan-SQ-FS', 'BM25+Flan-SQ-ZS'],\n",
    "    eval_metrics=['recall_1000', 'ndcg_cut_5', 'ndcg_cut.10', 'recip_rank']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recall_1000</th>\n",
       "      <th>ndcg_cut_5</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>recip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prototype1</td>\n",
       "      <td>0.806138</td>\n",
       "      <td>0.542748</td>\n",
       "      <td>0.511496</td>\n",
       "      <td>0.876778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prototype2</td>\n",
       "      <td>0.803869</td>\n",
       "      <td>0.566553</td>\n",
       "      <td>0.532910</td>\n",
       "      <td>0.924430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prototype3</td>\n",
       "      <td>0.788942</td>\n",
       "      <td>0.534332</td>\n",
       "      <td>0.511348</td>\n",
       "      <td>0.952292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prototype4</td>\n",
       "      <td>0.806138</td>\n",
       "      <td>0.541391</td>\n",
       "      <td>0.506853</td>\n",
       "      <td>0.875463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prototype5</td>\n",
       "      <td>0.803869</td>\n",
       "      <td>0.562714</td>\n",
       "      <td>0.529252</td>\n",
       "      <td>0.930113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prototype6</td>\n",
       "      <td>0.788942</td>\n",
       "      <td>0.532035</td>\n",
       "      <td>0.505874</td>\n",
       "      <td>0.949333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Prototype7</td>\n",
       "      <td>0.794154</td>\n",
       "      <td>0.548624</td>\n",
       "      <td>0.516441</td>\n",
       "      <td>0.894783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Prototype8</td>\n",
       "      <td>0.794154</td>\n",
       "      <td>0.553862</td>\n",
       "      <td>0.520156</td>\n",
       "      <td>0.903796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Prototype9</td>\n",
       "      <td>0.806138</td>\n",
       "      <td>0.542748</td>\n",
       "      <td>0.511496</td>\n",
       "      <td>0.876778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  recall_1000  ndcg_cut_5  ndcg_cut.10  recip_rank\n",
       "0  Prototype1     0.806138    0.542748     0.511496    0.876778\n",
       "1  Prototype2     0.803869    0.566553     0.532910    0.924430\n",
       "2  Prototype3     0.788942    0.534332     0.511348    0.952292\n",
       "3  Prototype4     0.806138    0.541391     0.506853    0.875463\n",
       "4  Prototype5     0.803869    0.562714     0.529252    0.930113\n",
       "5  Prototype6     0.788942    0.532035     0.505874    0.949333\n",
       "6  Prototype7     0.794154    0.548624     0.516441    0.894783\n",
       "7  Prototype8     0.794154    0.553862     0.520156    0.903796\n",
       "8  Prototype9     0.806138    0.542748     0.511496    0.876778"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 =   pipeline_gpt_cot >> bm25_stopwords\n",
    "p2 = pipeline_llama_sq_zs >> bm25_stopwords\n",
    "p3 = bm25_bo1 >> bm25_stopwords\n",
    "p4 = p1 >> bm25\n",
    "p5 = p2 >> bm25\n",
    "p6 = p3 >> bm25\n",
    "\n",
    "p7 = bm25_stopwords >> pipeline_gpt_cot\n",
    "p8 = p7 >> bm25_stopwords\n",
    "p9 = p4 >> bm25_stopwords\n",
    "\n",
    "pt.Experiment(\n",
    "    retr_systems=[p1, p2, p3, p4, p5, p6, p7, p8, p9],\n",
    "    topics=pt_dataset.get_topics('text'),\n",
    "    qrels=pt_dataset.get_qrels(),\n",
    "    names=['Prototype1', 'Prototype2', 'Prototype3', 'Prototype4', 'Prototype5', 'Prototype6', 'Prototype7', 'Prototype8', 'Prototype9'],\n",
    "    eval_metrics=['recall_1000', 'ndcg_cut_5', 'ndcg_cut.10', 'recip_rank']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
