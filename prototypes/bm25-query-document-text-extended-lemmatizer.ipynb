{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import All Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure necessary libraries are imported\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "from tqdm import tqdm\n",
    "from jnius import autoclass\n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "\n",
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "tira = Client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset and the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "dataset = 'antique-test-20230107-training'\n",
    "pt_dataset = pt.get_dataset(f'irds:ir-benchmarks/{dataset}')\n",
    "bm25 = tira.pt.from_submission('ir-benchmarks/tira-ir-starter/BM25 Re-Rank (tira-ir-starter-pyterrier)', dataset)\n",
    "\n",
    "# A (pre-built) PyTerrier index loaded from TIRA\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Expansion by Query Prediction with docT5query\n",
    "The basic idea is to train a model, that when given an input document, generates questions that the document might answer (or more broadly, queries for which the document might be relevant). These predicted questions (or queries) are then appended to the original documents, which are then indexed as before. The docT5query model gets its name from the use of T5 as the expansion model.\n",
    "\n",
    "The primary advantage of this approach is that expensive neural inference is pushed to indexing time, which means that \"bag of words\" queries against an inverted index built on the augmented document collection are only slightly slower (due to longer documents) — but the retrieval results are much better.\n",
    "\n",
    "First we check, if our corpus has a high recall or a lower. Our Corpus in this case is the union of the IR Anthology and the ACL Anthology. The recall may change if we use another corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recall_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  recall_1000\n",
       "0  BM25     0.788732"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "pt.Experiment(\n",
    "    retr_systems=[bm25],\n",
    "    topics=pt_dataset.get_topics('text'),\n",
    "    qrels=pt_dataset.get_qrels(),\n",
    "    names=['BM25'],\n",
    "    eval_metrics=['recall_1000']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have already a high recall. This is important for the way we implement the docT5query.\n",
    "More information about the implementation in the [Tutorial](https://github.com/tira-io/teaching-ir-with-shared-tasks/blob/main/tutorials/tutorial-doc-t5-query.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_t5_query(dataset):\n",
    "    docs = tira.get_run_output('ir-benchmarks/seanmacavaney/DocT5Query', dataset) + '/documents.jsonl.gz'\n",
    "    with gzip.open(docs, 'rt') as f:\n",
    "        for l in tqdm(f):\n",
    "            l = json.loads(l)\n",
    "            l['text'] = l['querygen']\n",
    "            l['docno'] = l['doc_id']\n",
    "            del l['doc_id']\n",
    "            del l['querygen']\n",
    "            yield l\n",
    "\n",
    "def doc_t5_query_index(dataset):\n",
    "    indexer = pt.IterDictIndexer(\"/tmp/index2\", overwrite=True, meta={'docno': 100, 'text': 20480})\n",
    "    index_ref = indexer.index(doc_t5_query(dataset))\n",
    "    return pt.IndexFactory.of(index_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "928it [00:00, 9101.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3302it [00:00, 11282.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:45:00.196 [ForkJoinPool-7-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (3052500_1) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "403666it [00:31, 12870.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:45:33.502 [ForkJoinPool-7-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 113 empty documents\n"
     ]
    }
   ],
   "source": [
    "indexD = doc_t5_query_index(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188633it [00:07, 24258.53it/s]\n"
     ]
    }
   ],
   "source": [
    "docs_retrieved_by_bm25 = {}\n",
    "\n",
    "bm25_result = bm25(pt_dataset.get_topics('title'))\n",
    "\n",
    "for _, i in tqdm(bm25_result.iterrows()):\n",
    "    qid, docno = str(i['qid']), str(i['docno'])\n",
    "\n",
    "    if qid not in docs_retrieved_by_bm25:\n",
    "        docs_retrieved_by_bm25[qid] = set()\n",
    "    \n",
    "    docs_retrieved_by_bm25[qid].add(docno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "omit_already_retrieved_docs = lambda i: i[i.apply(lambda j: str(j['docno']) not in docs_retrieved_by_bm25[str(j['qid'])], axis=1)]\n",
    "omit_already_retrieved_docs = pt.apply.generic(omit_already_retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_doct5query = pt.BatchRetrieve(indexD, wmodel=\"BM25\")\n",
    "bm25_doct5query_new = bm25_doct5query >> omit_already_retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-benchmarks/antique-test-20230107-training documents:   0%|          | 1654/403666 [00:00<00:46, 8728.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:45:48.006 [ForkJoinPool-8-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (2824443_2) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-benchmarks/antique-test-20230107-training documents: 100%|██████████| 403666/403666 [00:36<00:00, 11165.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:46:27.345 [ForkJoinPool-8-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 1570 empty documents\n"
     ]
    }
   ],
   "source": [
    "def create_index(documents, stopwords):\n",
    "    indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, meta={'docno': 100, 'text': 20480}, stopwords=customStopwords)\n",
    "    index_ref = indexer.index(documents)\n",
    "    return pt.IndexFactory.of(index_ref)\n",
    "\n",
    "customStopwords =[\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', \n",
    "    'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', \n",
    "    'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', \n",
    "    'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', \n",
    "    'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', \n",
    "    'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', \n",
    "    'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', \n",
    "    'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', \n",
    "    'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', \n",
    "    'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', \n",
    "    'will', 'just', 'don', 'should', 'now'\n",
    "]\n",
    "\n",
    "index = create_index(pt_dataset.get_corpus_iter(), customStopwords)\n",
    "\n",
    "bm25_stopwords = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Expansion with Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_rm3 = bm25 >> pt.rewrite.RM3(index) >> bm25\n",
    "bm25_kl = bm25 >> pt.rewrite.KLQueryExpansion(index) >> bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm expansions with gpt\n",
    "gpt_cot = tira.pt.transform_queries('workshop-on-open-web-search/tu-dresden-03/qe-gpt3.5-cot', dataset, prefix='llm_expansion_')\n",
    "gpt_sq_fs = tira.pt.transform_queries('workshop-on-open-web-search/tu-dresden-03/qe-gpt3.5-sq-fs', dataset, prefix='llm_expansion_')\n",
    "gpt_sq_zs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-gpt3.5-sq-zs', dataset, prefix='llm_expansion_')\n",
    "\n",
    "# llm expansions with llama\n",
    "llama_cot = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-llama-cot', dataset, prefix='llm_expansion_')\n",
    "llama_sq_fs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-llama-sq-fs', dataset, prefix='llm_expansion_')\n",
    "llama_sq_zs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-llama-sq-zs', dataset, prefix='llm_expansion_')\n",
    "\n",
    "# llm expansions with flan-ul2\n",
    "flan_cot = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-flan-ul2-cot', dataset, prefix='llm_expansion_')\n",
    "flan_sq_fs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-flan-ul2-sq-fs', dataset, prefix='llm_expansion_')\n",
    "flan_sq_zs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-flan-ul2-sq-zs', dataset, prefix='llm_expansion_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = pt.autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()\n",
    "\n",
    "def pt_tokenize(text):\n",
    "    return ' '.join(tokeniser.getTokens(text))\n",
    "\n",
    "def expand_query(topic):\n",
    "  ret = ' '.join([topic['query'], topic['query'], topic['query'],  topic['query'],  topic['query'], topic['llm_expansion_query']])\n",
    "\n",
    "  # apply the tokenization\n",
    "  return pt_tokenize(ret)\n",
    "\n",
    "# we wrap this into an pyterrier transformer\n",
    "# Documentation: https://pyterrier.readthedocs.io/en/latest/apply.html\n",
    "pt_expand_query = pt.apply.query(expand_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_tokenize(text):\n",
    "    return ' '.join(tokeniser.getTokens(text))\n",
    "\n",
    "def expand_and_lemmatize_query(topic):\n",
    "    expanded_query = ' '.join([topic['query'], topic['query'], topic['query'],  topic['query'],  topic['query'], topic['llm_expansion_query']])\n",
    "    lemmatized_query = lemmatize_text(expanded_query)\n",
    "    return pt_tokenize(lemmatized_query)\n",
    "\n",
    "pt_expand_and_lemmatize_query = pt.apply.query(expand_and_lemmatize_query)\n",
    "\n",
    "pipeline_gpt_cot = (gpt_cot >> pt_expand_and_lemmatize_query) >> bm25\n",
    "pipeline_gpt_sq_fs = (gpt_sq_fs >> pt_expand_and_lemmatize_query) >> bm25\n",
    "pipeline_gpt_sq_zs = (gpt_sq_zs >> pt_expand_and_lemmatize_query) >> bm25\n",
    "\n",
    "pipeline_llama_cot = (llama_cot >> pt_expand_and_lemmatize_query) >> bm25\n",
    "pipeline_llama_sq_fs = (llama_sq_fs >> pt_expand_and_lemmatize_query) >> bm25\n",
    "pipeline_llama_sq_zs = (llama_sq_zs >> pt_expand_and_lemmatize_query) >> bm25\n",
    "\n",
    "pipeline_flan_cot = (flan_cot >> pt_expand_and_lemmatize_query) >> bm25\n",
    "pipeline_flan_sq_fs = (flan_sq_fs >> pt_expand_and_lemmatize_query) >> bm25\n",
    "pipeline_flan_sq_zs = (flan_sq_zs >> pt_expand_and_lemmatize_query) >> bm25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bo1 Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo1_expansion = bm25_doct5query_new >> pt.rewrite.Bo1QueryExpansion(index)\n",
    "# build final pipeline for retrieval\n",
    "bm25_bo1 = bo1_expansion >> bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recall_1000</th>\n",
       "      <th>ndcg_cut_5</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>recip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.529428</td>\n",
       "      <td>0.510402</td>\n",
       "      <td>0.934803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-3.5 CoT</td>\n",
       "      <td>0.803464</td>\n",
       "      <td>0.535214</td>\n",
       "      <td>0.505071</td>\n",
       "      <td>0.866274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-3.5 SQ FS</td>\n",
       "      <td>0.794062</td>\n",
       "      <td>0.536776</td>\n",
       "      <td>0.512088</td>\n",
       "      <td>0.923202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT-3.5 SQ ZS</td>\n",
       "      <td>0.786726</td>\n",
       "      <td>0.530052</td>\n",
       "      <td>0.496447</td>\n",
       "      <td>0.915797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LLAMA CoT</td>\n",
       "      <td>0.789377</td>\n",
       "      <td>0.518131</td>\n",
       "      <td>0.489208</td>\n",
       "      <td>0.857129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LLAMA SQ FS</td>\n",
       "      <td>0.793214</td>\n",
       "      <td>0.543543</td>\n",
       "      <td>0.509856</td>\n",
       "      <td>0.923370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LLAMA SQ ZS</td>\n",
       "      <td>0.799414</td>\n",
       "      <td>0.557042</td>\n",
       "      <td>0.522821</td>\n",
       "      <td>0.921519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FLAN-UL2 CoT</td>\n",
       "      <td>0.792891</td>\n",
       "      <td>0.513493</td>\n",
       "      <td>0.489407</td>\n",
       "      <td>0.886051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FLAN-UL2 SQ FS</td>\n",
       "      <td>0.787538</td>\n",
       "      <td>0.525658</td>\n",
       "      <td>0.503038</td>\n",
       "      <td>0.917737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FLAN-UL2 SQ ZS</td>\n",
       "      <td>0.795934</td>\n",
       "      <td>0.522575</td>\n",
       "      <td>0.499660</td>\n",
       "      <td>0.895438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BM25 + Bo1</td>\n",
       "      <td>0.781723</td>\n",
       "      <td>0.519123</td>\n",
       "      <td>0.501171</td>\n",
       "      <td>0.913488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  recall_1000  ndcg_cut_5  ndcg_cut_10  recip_rank\n",
       "0             BM25     0.788732    0.529428     0.510402    0.934803\n",
       "1      GPT-3.5 CoT     0.803464    0.535214     0.505071    0.866274\n",
       "2    GPT-3.5 SQ FS     0.794062    0.536776     0.512088    0.923202\n",
       "3    GPT-3.5 SQ ZS     0.786726    0.530052     0.496447    0.915797\n",
       "4        LLAMA CoT     0.789377    0.518131     0.489208    0.857129\n",
       "5      LLAMA SQ FS     0.793214    0.543543     0.509856    0.923370\n",
       "6      LLAMA SQ ZS     0.799414    0.557042     0.522821    0.921519\n",
       "7     FLAN-UL2 CoT     0.792891    0.513493     0.489407    0.886051\n",
       "8   FLAN-UL2 SQ FS     0.787538    0.525658     0.503038    0.917737\n",
       "9   FLAN-UL2 SQ ZS     0.795934    0.522575     0.499660    0.895438\n",
       "10      BM25 + Bo1     0.781723    0.519123     0.501171    0.913488"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate with the new lemmatized index and query pipelines\n",
    "pt.Experiment(\n",
    "    retr_systems=[bm25, pipeline_gpt_cot, pipeline_gpt_sq_fs, pipeline_gpt_sq_zs,\n",
    "                  pipeline_llama_cot, pipeline_llama_sq_fs, pipeline_llama_sq_zs,\n",
    "                  pipeline_flan_cot, pipeline_flan_sq_fs, pipeline_flan_sq_zs, bm25_bo1],\n",
    "    topics=pt_dataset.get_topics('text'),\n",
    "    qrels=pt_dataset.get_qrels(),\n",
    "    names=['BM25', 'GPT-3.5 CoT', 'GPT-3.5 SQ FS', 'GPT-3.5 SQ ZS',\n",
    "           'LLAMA CoT', 'LLAMA SQ FS', 'LLAMA SQ ZS',\n",
    "           'FLAN-UL2 CoT', 'FLAN-UL2 SQ FS', 'FLAN-UL2 SQ ZS', 'BM25 + Bo1'],\n",
    "    eval_metrics=['recall_1000', 'ndcg_cut_5', 'ndcg_cut_10', 'recip_rank']\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
