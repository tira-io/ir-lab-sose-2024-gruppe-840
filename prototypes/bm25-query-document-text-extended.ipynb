{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import All Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "ensure_pyterrier_is_loaded()\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "from tqdm import tqdm\n",
    "from jnius import autoclass\n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset and the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "dataset = 'antique-test-20230107-training'\n",
    "pt_dataset = pt.get_dataset(f'irds:ir-benchmarks/{dataset}')\n",
    "bm25 = tira.pt.from_submission('ir-benchmarks/tira-ir-starter/BM25 Re-Rank (tira-ir-starter-pyterrier)', dataset)\n",
    "\n",
    "# A (pre-built) PyTerrier index loaded from TIRA\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Expansion by Query Prediction with docT5query\n",
    "The basic idea is to train a model, that when given an input document, generates questions that the document might answer (or more broadly, queries for which the document might be relevant). These predicted questions (or queries) are then appended to the original documents, which are then indexed as before. The docT5query model gets its name from the use of T5 as the expansion model.\n",
    "\n",
    "The primary advantage of this approach is that expensive neural inference is pushed to indexing time, which means that \"bag of words\" queries against an inverted index built on the augmented document collection are only slightly slower (due to longer documents) — but the retrieval results are much better.\n",
    "\n",
    "First we check, if our corpus has a high recall or a lower. Our Corpus in this case is the union of the IR Anthology and the ACL Anthology. The recall may change if we use another corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recall_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  recall_1000\n",
       "0  BM25     0.788732"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "pt.Experiment(\n",
    "    retr_systems=[bm25],\n",
    "    topics=pt_dataset.get_topics('text'),\n",
    "    qrels=pt_dataset.get_qrels(),\n",
    "    names=['BM25'],\n",
    "    eval_metrics=['recall_1000']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have already a high recall. This is important for the way we implement the docT5query.\n",
    "More information about the implementation in the [Tutorial](https://github.com/tira-io/teaching-ir-with-shared-tasks/blob/main/tutorials/tutorial-doc-t5-query.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_t5_query(dataset):\n",
    "    docs = tira.get_run_output('ir-benchmarks/seanmacavaney/DocT5Query', dataset) + '/documents.jsonl.gz'\n",
    "    with gzip.open(docs, 'rt') as f:\n",
    "        for l in tqdm(f):\n",
    "            l = json.loads(l)\n",
    "            l['text'] = l['querygen']\n",
    "            l['docno'] = l['doc_id']\n",
    "            del l['doc_id']\n",
    "            del l['querygen']\n",
    "            yield l\n",
    "\n",
    "def doc_t5_query_index(dataset):\n",
    "    indexer = pt.IterDictIndexer(\"/tmp/index2\", overwrite=True, meta={'docno': 100, 'text': 20480})\n",
    "    index_ref = indexer.index(doc_t5_query(dataset))\n",
    "    return pt.IndexFactory.of(index_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:03:25.536 [ForkJoinPool-16-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (3052500_1) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "403666it [00:27, 14603.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:03:55.057 [ForkJoinPool-16-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 113 empty documents\n"
     ]
    }
   ],
   "source": [
    "indexD = doc_t5_query_index(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188633it [00:07, 23826.40it/s]\n"
     ]
    }
   ],
   "source": [
    "docs_retrieved_by_bm25 = {}\n",
    "\n",
    "bm25_result = bm25(pt_dataset.get_topics('title'))\n",
    "\n",
    "for _, i in tqdm(bm25_result.iterrows()):\n",
    "    qid, docno = str(i['qid']), str(i['docno'])\n",
    "\n",
    "    if qid not in docs_retrieved_by_bm25:\n",
    "        docs_retrieved_by_bm25[qid] = set()\n",
    "    \n",
    "    docs_retrieved_by_bm25[qid].add(docno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "omit_already_retrieved_docs = lambda i: i[i.apply(lambda j: str(j['docno']) not in docs_retrieved_by_bm25[str(j['qid'])], axis=1)]\n",
    "omit_already_retrieved_docs = pt.apply.generic(omit_already_retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_doct5query = pt.BatchRetrieve(indexD, wmodel=\"BM25\")\n",
    "bm25_doct5query_new = bm25_doct5query >> omit_already_retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:44:27.228 [ForkJoinPool-22-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (2824443_2) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-benchmarks/antique-test-20230107-training documents: 100%|██████████| 403666/403666 [00:43<00:00, 9247.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:45:14.472 [ForkJoinPool-22-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 1570 empty documents\n"
     ]
    }
   ],
   "source": [
    "def create_index(documents, stopwords):\n",
    "    indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, meta={'docno': 100, 'text': 20480}, stopwords=customStopwords)\n",
    "    index_ref = indexer.index(documents)\n",
    "    return pt.IndexFactory.of(index_ref)\n",
    "\n",
    "customStopwords =[\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', \n",
    "    'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', \n",
    "    'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', \n",
    "    'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', \n",
    "    'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', \n",
    "    'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', \n",
    "    'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', \n",
    "    'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', \n",
    "    'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', \n",
    "    'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', \n",
    "    'will', 'just', 'don', 'should', 'now'\n",
    "]\n",
    "\n",
    "index = create_index(pt_dataset.get_corpus_iter(), customStopwords)\n",
    "\n",
    "bm25_stopwords = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Expansion with Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_rm3 = bm25 >> pt.rewrite.RM3(index) >> bm25\n",
    "bm25_kl = bm25 >> pt.rewrite.KLQueryExpansion(index) >> bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 63.0kiB [00:00, 1.81MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /root/.tira/extracted_runs/workshop-on-open-web-search/antique-test-20230107-training/tu-dresden-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 7.69kiB [00:00, 29.6MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /root/.tira/extracted_runs/workshop-on-open-web-search/antique-test-20230107-training/tu-dresden-03\n",
      "Download from Zenodo: https://zenodo.org/records/10852738/files/tu-dresden-03-qe-gpt3.5-sq-zs-tiny-test-collections.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 100%|██████████| 95.1k/95.1k [00:00<00:00, 2.30MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /root/.tira/extracted_runs/ir-benchmarks/antique-test-20230107-training/tu-dresden-03\n",
      "Download from Zenodo: https://zenodo.org/records/10852738/files/tu-dresden-03-qe-llama-cot-tiny-test-collections.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 100%|██████████| 215k/215k [00:00<00:00, 3.56MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /root/.tira/extracted_runs/ir-benchmarks/antique-test-20230107-training/tu-dresden-03\n",
      "Download from Zenodo: https://zenodo.org/records/10852738/files/tu-dresden-03-qe-llama-sq-fs-tiny-test-collections.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 100%|██████████| 35.1k/35.1k [00:00<00:00, 853kiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /root/.tira/extracted_runs/ir-benchmarks/antique-test-20230107-training/tu-dresden-03\n",
      "Download from Zenodo: https://zenodo.org/records/10852738/files/tu-dresden-03-qe-llama-sq-zs-tiny-test-collections.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 100%|██████████| 107k/107k [00:00<00:00, 2.96MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /root/.tira/extracted_runs/ir-benchmarks/antique-test-20230107-training/tu-dresden-03\n",
      "Download from Zenodo: https://zenodo.org/records/10852738/files/tu-dresden-03-qe-flan-ul2-cot-tiny-test-collections.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 100%|██████████| 64.5k/64.5k [00:00<00:00, 1.46MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /root/.tira/extracted_runs/ir-benchmarks/antique-test-20230107-training/tu-dresden-03\n",
      "Download from Zenodo: https://zenodo.org/records/10852738/files/tu-dresden-03-qe-flan-ul2-sq-fs-tiny-test-collections.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 100%|██████████| 30.9k/30.9k [00:00<00:00, 1.84MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /root/.tira/extracted_runs/ir-benchmarks/antique-test-20230107-training/tu-dresden-03\n",
      "Download from Zenodo: https://zenodo.org/records/10852738/files/tu-dresden-03-qe-flan-ul2-sq-zs-tiny-test-collections.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 100%|██████████| 38.0k/38.0k [00:00<00:00, 743kiB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /root/.tira/extracted_runs/ir-benchmarks/antique-test-20230107-training/tu-dresden-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# llm expansions with gpt\n",
    "gpt_cot = tira.pt.transform_queries('workshop-on-open-web-search/tu-dresden-03/qe-gpt3.5-cot', dataset, prefix='llm_expansion_')\n",
    "gpt_sq_fs = tira.pt.transform_queries('workshop-on-open-web-search/tu-dresden-03/qe-gpt3.5-sq-fs', dataset, prefix='llm_expansion_')\n",
    "gpt_sq_zs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-gpt3.5-sq-zs', dataset, prefix='llm_expansion_')\n",
    "\n",
    "# llm expansions with llama\n",
    "llama_cot = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-llama-cot', dataset, prefix='llm_expansion_')\n",
    "llama_sq_fs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-llama-sq-fs', dataset, prefix='llm_expansion_')\n",
    "llama_sq_zs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-llama-sq-zs', dataset, prefix='llm_expansion_')\n",
    "\n",
    "# llm expansions with flan-ul2\n",
    "flan_cot = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-flan-ul2-cot', dataset, prefix='llm_expansion_')\n",
    "flan_sq_fs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-flan-ul2-sq-fs', dataset, prefix='llm_expansion_')\n",
    "flan_sq_zs = tira.pt.transform_queries('ir-benchmarks/tu-dresden-03/qe-flan-ul2-sq-zs', dataset, prefix='llm_expansion_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = pt.autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()\n",
    "\n",
    "def pt_tokenize(text):\n",
    "    return ' '.join(tokeniser.getTokens(text))\n",
    "\n",
    "def expand_query(topic):\n",
    "  ret = ' '.join([topic['query'], topic['query'], topic['query'],  topic['query'],  topic['query'], topic['llm_expansion_query']])\n",
    "\n",
    "  # apply the tokenization\n",
    "  return pt_tokenize(ret)\n",
    "\n",
    "# we wrap this into an pyterrier transformer\n",
    "# Documentation: https://pyterrier.readthedocs.io/en/latest/apply.html\n",
    "pt_expand_query = pt.apply.query(expand_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_gpt_cot = (gpt_cot >> pt_expand_query) >> bm25\n",
    "pipeline_gpt_sq_fs = (gpt_sq_fs >> pt_expand_query) >> bm25\n",
    "pipeline_gpt_sq_zs = (gpt_sq_zs >> pt_expand_query) >> bm25\n",
    "\n",
    "pipeline_llama_cot = (llama_cot >> pt_expand_query) >> bm25\n",
    "pipeline_llama_sq_fs = (llama_sq_fs >> pt_expand_query) >> bm25\n",
    "pipeline_llama_sq_zs = (llama_sq_zs >> pt_expand_query) >> bm25\n",
    "\n",
    "pipeline_flan_cot = (flan_cot >> pt_expand_query) >> bm25\n",
    "pipeline_flan_sq_fs = (flan_sq_fs >> pt_expand_query) >> bm25\n",
    "pipeline_flan_sq_zs = (flan_sq_zs >> pt_expand_query) >> bm25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bo1 Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo1_expansion = bm25_doct5query_new >> pt.rewrite.Bo1QueryExpansion(index)\n",
    "# build final pipeline for retrieval\n",
    "bm25_bo1 = bo1_expansion >> bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recall_1000</th>\n",
       "      <th>ndcg_cut_5</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>recip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.529428</td>\n",
       "      <td>0.510402</td>\n",
       "      <td>0.934803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DocT5Query &gt;&gt; BM25</td>\n",
       "      <td>0.534685</td>\n",
       "      <td>0.399011</td>\n",
       "      <td>0.348678</td>\n",
       "      <td>0.793546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25_stopwords</td>\n",
       "      <td>0.794154</td>\n",
       "      <td>0.536473</td>\n",
       "      <td>0.516196</td>\n",
       "      <td>0.948333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BM25_Bo1</td>\n",
       "      <td>0.781723</td>\n",
       "      <td>0.519123</td>\n",
       "      <td>0.501171</td>\n",
       "      <td>0.913488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BM25+RM3</td>\n",
       "      <td>0.779805</td>\n",
       "      <td>0.509865</td>\n",
       "      <td>0.489359</td>\n",
       "      <td>0.934375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BM25+KL</td>\n",
       "      <td>0.788479</td>\n",
       "      <td>0.532529</td>\n",
       "      <td>0.503925</td>\n",
       "      <td>0.949333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BM25+GPT-COT</td>\n",
       "      <td>0.806138</td>\n",
       "      <td>0.541391</td>\n",
       "      <td>0.506853</td>\n",
       "      <td>0.875463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BM25+GPT-SQ-FS</td>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.541749</td>\n",
       "      <td>0.518511</td>\n",
       "      <td>0.938364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BM25+GPT-SQ-ZS</td>\n",
       "      <td>0.790430</td>\n",
       "      <td>0.536149</td>\n",
       "      <td>0.501605</td>\n",
       "      <td>0.921401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BM25+Llama-COT</td>\n",
       "      <td>0.793485</td>\n",
       "      <td>0.523303</td>\n",
       "      <td>0.495643</td>\n",
       "      <td>0.866429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BM25+Llama-SQ-FS</td>\n",
       "      <td>0.797566</td>\n",
       "      <td>0.547980</td>\n",
       "      <td>0.517811</td>\n",
       "      <td>0.936454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BM25+Llama-SQ-ZS</td>\n",
       "      <td>0.803869</td>\n",
       "      <td>0.562714</td>\n",
       "      <td>0.529252</td>\n",
       "      <td>0.930113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BM25+Flan-COT</td>\n",
       "      <td>0.796139</td>\n",
       "      <td>0.521862</td>\n",
       "      <td>0.496685</td>\n",
       "      <td>0.895637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BM25+Flan-SQ-FS</td>\n",
       "      <td>0.791370</td>\n",
       "      <td>0.531894</td>\n",
       "      <td>0.507946</td>\n",
       "      <td>0.932898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BM25+Flan-SQ-ZS</td>\n",
       "      <td>0.798648</td>\n",
       "      <td>0.525873</td>\n",
       "      <td>0.502075</td>\n",
       "      <td>0.898631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  recall_1000  ndcg_cut_5  ndcg_cut.10  recip_rank\n",
       "0                 BM25     0.788732    0.529428     0.510402    0.934803\n",
       "1   DocT5Query >> BM25     0.534685    0.399011     0.348678    0.793546\n",
       "2       BM25_stopwords     0.794154    0.536473     0.516196    0.948333\n",
       "3             BM25_Bo1     0.781723    0.519123     0.501171    0.913488\n",
       "4             BM25+RM3     0.779805    0.509865     0.489359    0.934375\n",
       "5              BM25+KL     0.788479    0.532529     0.503925    0.949333\n",
       "6         BM25+GPT-COT     0.806138    0.541391     0.506853    0.875463\n",
       "7       BM25+GPT-SQ-FS     0.797366    0.541749     0.518511    0.938364\n",
       "8       BM25+GPT-SQ-ZS     0.790430    0.536149     0.501605    0.921401\n",
       "9       BM25+Llama-COT     0.793485    0.523303     0.495643    0.866429\n",
       "10    BM25+Llama-SQ-FS     0.797566    0.547980     0.517811    0.936454\n",
       "11    BM25+Llama-SQ-ZS     0.803869    0.562714     0.529252    0.930113\n",
       "12       BM25+Flan-COT     0.796139    0.521862     0.496685    0.895637\n",
       "13     BM25+Flan-SQ-FS     0.791370    0.531894     0.507946    0.932898\n",
       "14     BM25+Flan-SQ-ZS     0.798648    0.525873     0.502075    0.898631"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    retr_systems=[bm25, bm25_doct5query, bm25_stopwords, bm25_bo1, bm25_rm3, bm25_kl, pipeline_gpt_cot, pipeline_gpt_sq_fs, pipeline_gpt_sq_zs, pipeline_llama_cot, pipeline_llama_sq_fs, pipeline_llama_sq_zs, pipeline_flan_cot, pipeline_flan_sq_fs, pipeline_flan_sq_zs],\n",
    "    topics=pt_dataset.get_topics('text'),\n",
    "    qrels=pt_dataset.get_qrels(),\n",
    "    names=['BM25', 'DocT5Query >> BM25', 'BM25_stopwords','BM25_Bo1', 'BM25+RM3', 'BM25+KL', 'BM25+GPT-COT', 'BM25+GPT-SQ-FS', 'BM25+GPT-SQ-ZS', 'BM25+Llama-COT', 'BM25+Llama-SQ-FS', 'BM25+Llama-SQ-ZS', 'BM25+Flan-COT', 'BM25+Flan-SQ-FS', 'BM25+Flan-SQ-ZS'],\n",
    "    eval_metrics=['recall_1000', 'ndcg_cut_5', 'ndcg_cut.10', 'recip_rank']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
